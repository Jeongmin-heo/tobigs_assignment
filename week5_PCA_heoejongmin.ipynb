{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 반갑습니다 13기 여러분\n",
    "\n",
    "과제를 진행해 볼게요\n",
    "\n",
    "혹시라도 도저히 모르겠거나 해결이 안되신다면 01040493041로 전화주시거나 카톡주세요!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ''' ? ''' 이 있는 부분을 채워주시면 됩니다\n",
    "\n",
    "나는 내 스타일로 하겠다 하시면 그냥 구현 하셔도 됩니다!!\n",
    "\n",
    "참고하셔야 하는 함수들은 링크 달아드렸으니 들어가서 확인해보세요"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) PCA의 과정을 한번 차근차근 밟아 볼거에요 잘 따라 오세요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.linalg as lin\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "#   기본 모듈들을 불러와 줍니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = [95, 91, 66, 94, 68, 63, 12, 73, 93, 51, 13, 70, 63, 63, 97, 56, 67, 96, 75, 6]\n",
    "x2 = [56, 27, 25, 1, 9, 80, 92, 69, 6, 25, 83, 82, 54, 97, 66, 93, 76, 59, 94, 9]\n",
    "x3 = [57, 34, 9, 79, 4, 77, 100, 42, 6, 96, 61, 66, 9, 25, 84, 46, 16, 63, 53, 30]\n",
    "\n",
    "#   설명변수 x1, x2, x3의 값이 이렇게 있네요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.stack((x1,x2,x3),axis=0)\n",
    "\n",
    "#설명변수들을 하나의 행렬로 만들어 줍니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.DataFrame(X.T,columns=['x1','x2','x3']) #하나의 행렬을 데이터프레임으로 만들고 각 변수의 이름을 지정해 주었습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>95</td>\n",
       "      <td>56</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>91</td>\n",
       "      <td>27</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>66</td>\n",
       "      <td>25</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>94</td>\n",
       "      <td>1</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>68</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>63</td>\n",
       "      <td>80</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>92</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>73</td>\n",
       "      <td>69</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>93</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>51</td>\n",
       "      <td>25</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>83</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>70</td>\n",
       "      <td>82</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>63</td>\n",
       "      <td>54</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>63</td>\n",
       "      <td>97</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>97</td>\n",
       "      <td>66</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>56</td>\n",
       "      <td>93</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>67</td>\n",
       "      <td>76</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>96</td>\n",
       "      <td>59</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>75</td>\n",
       "      <td>94</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    x1  x2   x3\n",
       "0   95  56   57\n",
       "1   91  27   34\n",
       "2   66  25    9\n",
       "3   94   1   79\n",
       "4   68   9    4\n",
       "5   63  80   77\n",
       "6   12  92  100\n",
       "7   73  69   42\n",
       "8   93   6    6\n",
       "9   51  25   96\n",
       "10  13  83   61\n",
       "11  70  82   66\n",
       "12  63  54    9\n",
       "13  63  97   25\n",
       "14  97  66   84\n",
       "15  56  93   46\n",
       "16  67  76   16\n",
       "17  96  59   63\n",
       "18  75  94   53\n",
       "19   6   9   30"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X #확인해 보았을때, 정상적으로 출력되는 것을 확인 할 수 있었습니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1-1) 먼저 PCA를 시작하기 전에 항상!!!!!! 데이터를 scaling 해주어야 해요\n",
    "\n",
    "https://datascienceschool.net/view-notebook/f43be7d6515b48c0beb909826993c856/ 를 참고하시면 도움이 될거에요"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "지금까지는 train set 과 test set을 분리해주기 전에 scaling을 해주어도 상관없다고 알고 있었지만 \n",
    "이번기회를 통해서 나누어 준후에 scaling을 하고 scaling한 data의 mean과 std에 맞춰서 test set을 scaling해야 한다는 사실을 알게 되었습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7.956598343146955e-17, 1.0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "scaler.fit(X)\n",
    "X_std = scaler.transform(X)\n",
    "np.mean(X_std), np.std(X_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = X_std.T #features라는 이름으로 지정하였습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.08573604,  0.93801686,  0.01477192,  1.04880625,  0.08863151,\n",
       "        -0.09601747, -1.97943714,  0.2732805 ,  1.01187645, -0.53917504,\n",
       "        -1.94250735,  0.16249111, -0.09601747, -0.09601747,  1.15959564,\n",
       "        -0.35452606,  0.05170172,  1.12266584,  0.3471401 , -2.20101593],\n",
       "       [ 0.02614175, -0.86575334, -0.92726334, -1.66538341, -1.41934339,\n",
       "         0.76426183,  1.13332186,  0.42595679, -1.5116084 , -0.92726334,\n",
       "         0.85652683,  0.82577183, -0.03536825,  1.28709688,  0.33369178,\n",
       "         1.16407687,  0.64124181,  0.11840676,  1.19483187, -1.41934339],\n",
       "       [ 0.30684189, -0.46445467, -1.30282049,  1.04460382, -1.47049366,\n",
       "         0.97753455,  1.74883111, -0.1961776 , -1.40342439,  1.61469258,\n",
       "         0.44098042,  0.60865359, -1.30282049, -0.76626636,  1.21227698,\n",
       "        -0.06203907, -1.06807806,  0.50804969,  0.17270336, -0.5985932 ]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1-2) 자 그럼 공분산 행렬을 구해볼게요\\\n",
    "\n",
    "https://docs.scipy.org/doc/numpy/reference/generated/numpy.cov.html 를 참고하시면 도움이 될거에요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cov_matrix = np.cov(features) #features에 대한 공분산 행렬을 출력하고 이를 cov_matrix라는 이름으로 저장해 보았습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.05263158, -0.2037104 , -0.12079228],\n",
       "       [-0.2037104 ,  1.05263158,  0.3125801 ],\n",
       "       [-0.12079228,  0.3125801 ,  1.05263158]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cov_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1-3) 이제 고유값과 고유벡터를 구해볼게요\n",
    "\n",
    "방법은 실습코드에 있어요!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Eigenvalue\n",
    "eigenvalues = (lin.eig(cov_matrix)[0])  #Eigenvalue를 확인하였습니다. \n",
    "#Eigenvector\n",
    "eigenvectors = (lin.eig(cov_matrix)[1]) #Eigenvector를 확인하였습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.48756162 0.94435407 0.72597904]\n",
      "[[ 0.47018528 -0.85137353 -0.23257022]\n",
      " [-0.64960236 -0.15545725 -0.74421087]\n",
      " [-0.59744671 -0.50099516  0.62614797]]\n"
     ]
    }
   ],
   "source": [
    "print(eigenvalues)\n",
    "print(eigenvectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = np.zeros((3,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat[0][0] = eigenvalues[0]\n",
    "mat[1][1] = eigenvalues[1]\n",
    "mat[2][2] = eigenvalues[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.48756162, 0.        , 0.        ],\n",
       "       [0.        , 0.94435407, 0.        ],\n",
       "       [0.        , 0.        , 0.72597904]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1-4) 자 이제 고유값 분해를 할 모든 준비가 되었어요 고유값 분해의 곱으로 원래 공분산 행렬을 구해보세요\n",
    "\n",
    "https://docs.scipy.org/doc/numpy/reference/generated/numpy.dot.html 를 참고해서 행렬 끼리 곱하시면 됩니다\n",
    "\n",
    "행렬 곱으로 eigenvector x mat x eigenvector.T 하면 될거에요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.05263158, -0.2037104 , -0.12079228],\n",
       "       [-0.2037104 ,  1.05263158,  0.3125801 ],\n",
       "       [-0.12079228,  0.3125801 ,  1.05263158]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(np.dot(eigenvectors,mat),eigenvectors.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1-5) 마지막으로 고유 벡터 축으로 값을 변환해 볼게요\n",
    "\n",
    "함수로 한번 정의해 보았어요\n",
    "\n",
    "https://docs.scipy.org/doc/numpy/reference/generated/numpy.concatenate.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_coordinates(X,eigenvectors):\n",
    "    for i in range(eigenvectors.shape[0]):\n",
    "        if i == 0:\n",
    "            new = [X.dot(eigenvectors.T[i])]\n",
    "        else:\n",
    "            new = np.concatenate((new,[X.dot(eigenvectors.T[i])]),axis=0)\n",
    "    return new.T\n",
    "\n",
    "# 모든 고유 벡터 축으로 데이터를 projection한 값입니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.31019368, -1.08215716, -0.07983642],\n",
       "       [ 1.28092404, -0.43132556,  0.13533091],\n",
       "       [ 1.38766381,  0.78428014, -0.12911446],\n",
       "       [ 0.95087515, -1.15737142,  1.6495519 ],\n",
       "       [ 1.84222365,  0.88189889,  0.11493111],\n",
       "       [-1.12563709, -0.52680338,  0.06564012],\n",
       "       [-2.71174416,  0.63290138,  0.71195473],\n",
       "       [-0.03100441, -0.20059783, -0.50339479],\n",
       "       [ 2.29618509,  0.07661447,  0.01087174],\n",
       "       [-0.61585248, -0.205764  ,  1.82651199],\n",
       "       [-1.73320252,  1.29971699,  0.09045178],\n",
       "       [-0.82366049, -0.57164535, -0.27123176],\n",
       "       [ 0.75619512,  0.73995175, -0.76710616],\n",
       "       [-0.42344386,  0.26555394, -1.41533681],\n",
       "       [-0.39581307, -1.64646874,  0.24104031],\n",
       "       [-0.88581498,  0.15195119, -0.82271209],\n",
       "       [ 0.24587691,  0.39139878, -1.15801831],\n",
       "       [ 0.14741103, -1.22874561, -0.03110396],\n",
       "       [-0.7161265 , -0.56781471, -0.86180345],\n",
       "       [ 0.24475107,  2.39442622,  1.19337361]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_coordinates(X_std,eigenvectors)\n",
    "\n",
    "# 새로운 축으로 변환되어 나타난 데이터들입니다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) PCA를 구현해 보세요\n",
    "\n",
    "위의 과정을 이해하셨다면 충분히 하실 수 있을거에요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def MYPCA(X,number):\n",
    "    scaler = StandardScaler() #위의 과정을 한번에 함수로 모아서 출력하도록 하였습니다. \n",
    "    scaler.fit(X)\n",
    "    x_std = scaler.transform(X)\n",
    "    features = x_std.T\n",
    "    cov_matrix = np.cov(features)\n",
    "\n",
    "    eigenvalues = (lin.eig(cov_matrix)[0])  \n",
    "    eigenvectors = (lin.eig(cov_matrix)[1])\n",
    "    \n",
    "    new_coordinates(x_std,eigenvectors)\n",
    "    \n",
    "    new_coordinate = new_coordinates(x_std,eigenvectors)\n",
    "    \n",
    "    index = eigenvalues.argsort()\n",
    "    index = list(index)\n",
    "    \n",
    "    for i in range(number):\n",
    "        if i==0:\n",
    "            new = [new_coordinate[:,index.index(i)]]\n",
    "        else:\n",
    "            new = np.concatenate(([new_coordinate[:,index.index(i)]],new),axis=0)\n",
    "    return new.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.31019368, -1.08215716, -0.07983642],\n",
       "       [ 1.28092404, -0.43132556,  0.13533091],\n",
       "       [ 1.38766381,  0.78428014, -0.12911446],\n",
       "       [ 0.95087515, -1.15737142,  1.6495519 ],\n",
       "       [ 1.84222365,  0.88189889,  0.11493111],\n",
       "       [-1.12563709, -0.52680338,  0.06564012],\n",
       "       [-2.71174416,  0.63290138,  0.71195473],\n",
       "       [-0.03100441, -0.20059783, -0.50339479],\n",
       "       [ 2.29618509,  0.07661447,  0.01087174],\n",
       "       [-0.61585248, -0.205764  ,  1.82651199],\n",
       "       [-1.73320252,  1.29971699,  0.09045178],\n",
       "       [-0.82366049, -0.57164535, -0.27123176],\n",
       "       [ 0.75619512,  0.73995175, -0.76710616],\n",
       "       [-0.42344386,  0.26555394, -1.41533681],\n",
       "       [-0.39581307, -1.64646874,  0.24104031],\n",
       "       [-0.88581498,  0.15195119, -0.82271209],\n",
       "       [ 0.24587691,  0.39139878, -1.15801831],\n",
       "       [ 0.14741103, -1.22874561, -0.03110396],\n",
       "       [-0.7161265 , -0.56781471, -0.86180345],\n",
       "       [ 0.24475107,  2.39442622,  1.19337361]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MYPCA(X,3) #기존의 값과 동일하게 출력되는 것을 확인할수 있었습니다. \n",
    "\n",
    "# 새로운 축으로 잘 변환되어서 나타나나요?\n",
    "# 위에서 했던 PCA랑은 차이가 있을 수 있어요 왜냐하면 위에서는 고유값이 큰 축 순서로 정렬을 안했었거든요"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) sklearn이랑 비교를 해볼까요?\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html 를 참고하시면 도움이 될거에요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7.956598343146955e-17, 1.0)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "scaler.fit(X)\n",
    "X_std = scaler.transform(X)\n",
    "np.mean(X_std), np.std(X_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA(copy=True, iterated_power='auto', n_components=3, random_state=None,\n",
       "    svd_solver='auto', tol=0.0, whiten=False)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=3)\n",
    "pca.fit(X_std) #X_std에 대해서 pca 기법을 fit 하였습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.31019368, -1.08215716, -0.07983642],\n",
       "       [-1.28092404, -0.43132556,  0.13533091],\n",
       "       [-1.38766381,  0.78428014, -0.12911446],\n",
       "       [-0.95087515, -1.15737142,  1.6495519 ],\n",
       "       [-1.84222365,  0.88189889,  0.11493111],\n",
       "       [ 1.12563709, -0.52680338,  0.06564012],\n",
       "       [ 2.71174416,  0.63290138,  0.71195473],\n",
       "       [ 0.03100441, -0.20059783, -0.50339479],\n",
       "       [-2.29618509,  0.07661447,  0.01087174],\n",
       "       [ 0.61585248, -0.205764  ,  1.82651199],\n",
       "       [ 1.73320252,  1.29971699,  0.09045178],\n",
       "       [ 0.82366049, -0.57164535, -0.27123176],\n",
       "       [-0.75619512,  0.73995175, -0.76710616],\n",
       "       [ 0.42344386,  0.26555394, -1.41533681],\n",
       "       [ 0.39581307, -1.64646874,  0.24104031],\n",
       "       [ 0.88581498,  0.15195119, -0.82271209],\n",
       "       [-0.24587691,  0.39139878, -1.15801831],\n",
       "       [-0.14741103, -1.22874561, -0.03110396],\n",
       "       [ 0.7161265 , -0.56781471, -0.86180345],\n",
       "       [-0.24475107,  2.39442622,  1.19337361]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.fit_transform(X_std) #동일하게 출력되는 것을 확인할 수 있습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.31019368, -1.08215716, -0.07983642],\n",
       "       [ 1.28092404, -0.43132556,  0.13533091],\n",
       "       [ 1.38766381,  0.78428014, -0.12911446],\n",
       "       [ 0.95087515, -1.15737142,  1.6495519 ],\n",
       "       [ 1.84222365,  0.88189889,  0.11493111],\n",
       "       [-1.12563709, -0.52680338,  0.06564012],\n",
       "       [-2.71174416,  0.63290138,  0.71195473],\n",
       "       [-0.03100441, -0.20059783, -0.50339479],\n",
       "       [ 2.29618509,  0.07661447,  0.01087174],\n",
       "       [-0.61585248, -0.205764  ,  1.82651199],\n",
       "       [-1.73320252,  1.29971699,  0.09045178],\n",
       "       [-0.82366049, -0.57164535, -0.27123176],\n",
       "       [ 0.75619512,  0.73995175, -0.76710616],\n",
       "       [-0.42344386,  0.26555394, -1.41533681],\n",
       "       [-0.39581307, -1.64646874,  0.24104031],\n",
       "       [-0.88581498,  0.15195119, -0.82271209],\n",
       "       [ 0.24587691,  0.39139878, -1.15801831],\n",
       "       [ 0.14741103, -1.22874561, -0.03110396],\n",
       "       [-0.7161265 , -0.56781471, -0.86180345],\n",
       "       [ 0.24475107,  2.39442622,  1.19337361]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MYPCA(X,3) #동일하게 출력되는 것을 확인할 수 있습니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4) MNIST data에 적용을 해볼게요!\n",
    "\n",
    "mnist data를 따로 내려받지 않게 압축파일에 같이 두었어요~!!!\n",
    "\n",
    "mnist-original.mat 파일과 같은 위치에서 주피터 노트북을 열어주세요~!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.linalg as lin\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_openml #정상적으로 import되지않아서 fetch_openml로 변경하여 실행하였습니다. \n",
    "from scipy import io\n",
    "%matplotlib inline\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# mnist 손글씨 데이터를 불러옵니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = io.loadmat('mnist-original.mat') \n",
    "X = mnist['data'].T\n",
    "y = mnist['label'].T #data를 불러오고 data와 label을 분리하였습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data information\n",
    "\n",
    "# 7만개의 작은 숫자 이미지\n",
    "# 행 열이 반대로 되어있음 -> 전치\n",
    "# grayscale 28x28 pixel = 784 feature\n",
    "# 각 picel은 0~255의 값\n",
    "# label = 1~10 label이 총 10개인거에 주목하자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 784 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
       "0       0       0       0       0       0       0       0       0       0   \n",
       "1       0       0       0       0       0       0       0       0       0   \n",
       "2       0       0       0       0       0       0       0       0       0   \n",
       "3       0       0       0       0       0       0       0       0       0   \n",
       "4       0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel9  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0       0  ...         0         0         0         0         0         0   \n",
       "1       0  ...         0         0         0         0         0         0   \n",
       "2       0  ...         0         0         0         0         0         0   \n",
       "3       0  ...         0         0         0         0         0         0   \n",
       "4       0  ...         0         0         0         0         0         0   \n",
       "\n",
       "   pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0  \n",
       "1         0         0         0         0  \n",
       "2         0         0         0         0  \n",
       "3         0         0         0         0  \n",
       "4         0         0         0         0  \n",
       "\n",
       "[5 rows x 784 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data를 각 픽셀에 이름붙여 표현\n",
    "feat_cols = [ 'pixel'+str(i) for i in range(X.shape[1]) ]\n",
    "df = pd.DataFrame(X,columns=feat_cols)\n",
    "df.head() #784개의 columns으로 구성된 data라는 것을 확인할 수 있었습니다 ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df에 라벨 y를 붙여서 데이터프레임 생성\n",
    "df['y'] = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69995</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69996</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69997</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69998</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69999</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70000 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
       "0           0       0       0       0       0       0       0       0       0   \n",
       "1           0       0       0       0       0       0       0       0       0   \n",
       "2           0       0       0       0       0       0       0       0       0   \n",
       "3           0       0       0       0       0       0       0       0       0   \n",
       "4           0       0       0       0       0       0       0       0       0   \n",
       "...       ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "69995       0       0       0       0       0       0       0       0       0   \n",
       "69996       0       0       0       0       0       0       0       0       0   \n",
       "69997       0       0       0       0       0       0       0       0       0   \n",
       "69998       0       0       0       0       0       0       0       0       0   \n",
       "69999       0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "       pixel9  ...  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0           0  ...         0         0         0         0         0   \n",
       "1           0  ...         0         0         0         0         0   \n",
       "2           0  ...         0         0         0         0         0   \n",
       "3           0  ...         0         0         0         0         0   \n",
       "4           0  ...         0         0         0         0         0   \n",
       "...       ...  ...       ...       ...       ...       ...       ...   \n",
       "69995       0  ...         0         0         0         0         0   \n",
       "69996       0  ...         0         0         0         0         0   \n",
       "69997       0  ...         0         0         0         0         0   \n",
       "69998       0  ...         0         0         0         0         0   \n",
       "69999       0  ...         0         0         0         0         0   \n",
       "\n",
       "       pixel780  pixel781  pixel782  pixel783    y  \n",
       "0             0         0         0         0  0.0  \n",
       "1             0         0         0         0  0.0  \n",
       "2             0         0         0         0  0.0  \n",
       "3             0         0         0         0  0.0  \n",
       "4             0         0         0         0  0.0  \n",
       "...         ...       ...       ...       ...  ...  \n",
       "69995         0         0         0         0  9.0  \n",
       "69996         0         0         0         0  9.0  \n",
       "69997         0         0         0         0  9.0  \n",
       "69998         0         0         0         0  9.0  \n",
       "69999         0         0         0         0  9.0  \n",
       "\n",
       "[70000 rows x 785 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df #y를 추가하게 되어 785개의 컬럼을 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 지금까지 배운 여러 머신러닝 기법들이 있을거에요\n",
    "\n",
    "4-1) train_test_split을 통해 데이터를 0.8 0.2의 비율로 분할 해 주시고요\n",
    "\n",
    "4-2) PCA를 이용하여 mnist data를 축소해서 학습을 해주세요 / test error가 제일 작으신 분께 상품을 드리겠습니다 ^0^\n",
    "\n",
    "특정한 틀 없이 자유롭게 하시면 됩니다!!!!!!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "#요구사항대로 trian과 test를 0.8대 0.2의 비율로 나누어주었습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "scaler.fit(X_train)\n",
    "X_train_std = scaler.transform(X_train)\n",
    "#standardScaler를 활용하여 train에 대해서 X_train_std라는 이름으로 스케일링을 진행하였스비낟. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_std = scaler.transform(X_test) #test에 대해서도 fit한 data를 토대로 transform하였습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA(copy=True, iterated_power='auto', n_components=470, random_state=None,\n",
       "    svd_solver='auto', tol=0.0, whiten=False)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=470)\n",
    "pca.fit(X_train_std) #X_train_std를 pca를 통하여 fit하였습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[40.79126759 29.1610896  26.91195357 20.78202951 18.1265541  15.74719981\n",
      " 13.80325716 12.4749181  10.99234444  9.99763657  9.65704882  8.6160301\n",
      "  7.99829153  7.79509686  7.35102872  7.14385972  6.66492286  6.62815177\n",
      "  6.3588304   6.22214089  5.93176291  5.74328602  5.50595347  5.33688702\n",
      "  5.14875046  4.9489205   4.90648785  4.69014576  4.52389137  4.38846671\n",
      "  4.29568813  4.24031998  4.08997746  3.99430044  3.9663075   3.85200693\n",
      "  3.80101647  3.70909128  3.64692884  3.52018058  3.44986404  3.36472857\n",
      "  3.31414925  3.25453899  3.23382113  3.18037299  3.1639647   3.15289345\n",
      "  3.08442304  3.01151454  2.94478551  2.91780083  2.85411907  2.82761969\n",
      "  2.80021556  2.74983469  2.70206747  2.66864323  2.60393731  2.58210254\n",
      "  2.53624037  2.50933483  2.48585987  2.46789678  2.44929477  2.38529875\n",
      "  2.36509088  2.31810705  2.27690461  2.26273164  2.24340925  2.22148615\n",
      "  2.20734524  2.17562546  2.14658754  2.13511425  2.10996869  2.09742617\n",
      "  2.07393307  2.05916292  2.02600775  2.0219905   2.00223179  2.00092868\n",
      "  1.98483018  1.97450369  1.97228435  1.96875006  1.95499509  1.92416682\n",
      "  1.91545443  1.89706551  1.87437062  1.85875265  1.83159763  1.82297374\n",
      "  1.81122717  1.79495219  1.78960722  1.75918606  1.74732753  1.73762959\n",
      "  1.71929971  1.70703095  1.67443374  1.66615657  1.62901223  1.62321691\n",
      "  1.61217552  1.61036011  1.58743641  1.57441618  1.53587025  1.53098807\n",
      "  1.51296878  1.50401469  1.48792273  1.47880411  1.45367971  1.43962062\n",
      "  1.42116805  1.41057972  1.39848002  1.39318185  1.3800547   1.37047522\n",
      "  1.35830418  1.35604751  1.31775225  1.30873746  1.29680883  1.2800222\n",
      "  1.272461    1.2679723   1.25850174  1.25435669  1.2442647   1.23179648\n",
      "  1.20822468  1.19695202  1.1943701   1.18279902  1.16830224  1.1589752\n",
      "  1.15397866  1.14831287  1.14036064  1.11945703  1.11505025  1.10506794\n",
      "  1.09434065  1.09175072  1.07014958  1.0687243   1.05565948  1.05196292\n",
      "  1.03847686  1.03400191  1.01999049  1.01623453  1.01259544  1.0065673\n",
      "  1.00044688  1.00011551  0.99920916  0.99792417  0.98682533  0.98146266\n",
      "  0.97518472  0.97152082  0.96782955  0.95876302  0.94943746  0.93751104\n",
      "  0.92998237  0.91636294  0.91409654  0.90760879  0.8971688   0.88869019\n",
      "  0.88244603  0.87530076  0.86534391  0.86251952  0.85420664  0.84164264\n",
      "  0.84129497  0.83107441  0.82131342  0.81863612  0.81019632  0.80548823\n",
      "  0.80408083  0.79096865  0.78357456  0.77781886  0.77370261  0.76143173\n",
      "  0.75321062  0.75073233  0.74153867  0.73060579  0.72522745  0.71736194\n",
      "  0.71600523  0.70372088  0.69628085  0.69050645  0.68621941  0.67953479\n",
      "  0.67773586  0.67276656  0.66479122  0.65997884  0.64882161  0.64706643\n",
      "  0.63859683  0.63277178  0.62320929  0.61988386  0.61897864  0.6164008\n",
      "  0.60465211  0.60136939  0.59732946  0.59034824  0.57963727  0.5775175\n",
      "  0.57390598  0.56610092  0.56383199  0.56207327  0.55850385  0.55214517\n",
      "  0.54649361  0.54241076  0.53771674  0.52772469  0.52544679  0.52009563\n",
      "  0.51567538  0.51229664  0.50448885  0.50379782  0.49819484  0.49395971\n",
      "  0.49167524  0.4881698   0.48230978  0.47787042  0.47522111  0.47245425\n",
      "  0.46878657  0.46584182  0.4636959   0.45691363  0.45359049  0.45011832\n",
      "  0.44449938  0.43970716  0.439024    0.43375763  0.43234843  0.4289486\n",
      "  0.42659294  0.41420871  0.41276449  0.40969193  0.40521776  0.40415549\n",
      "  0.40208689  0.39849509  0.39246608  0.39116238  0.38855601  0.38430535\n",
      "  0.3830515   0.37636859  0.37531496  0.37176555  0.36796068  0.36543893\n",
      "  0.36379217  0.36071412  0.35675691  0.35503118  0.35136674  0.34989716\n",
      "  0.34590852  0.34387494  0.34178267  0.33815208  0.33291275  0.32887891\n",
      "  0.32838174  0.32727515  0.32278208  0.32093999  0.31889361  0.31392093\n",
      "  0.31265411  0.31093533  0.30874702  0.306424    0.30314843  0.30025739\n",
      "  0.29836477  0.2955367   0.29270893  0.28991637  0.2894437   0.28684785\n",
      "  0.28315046  0.28276284  0.28117545  0.27922308  0.27847956  0.27707803\n",
      "  0.27363627  0.27145592  0.26948199  0.26861115  0.26599837  0.26478099\n",
      "  0.2629834   0.25842663  0.25648414  0.25485471  0.25390589  0.25254392\n",
      "  0.25204532  0.24826593  0.24758573  0.24660463  0.24378476  0.24039464\n",
      "  0.239901    0.23760718  0.23542401  0.23454857  0.23206347  0.23052218\n",
      "  0.22937983  0.22887606  0.22816272  0.2257165   0.22427386  0.22289384\n",
      "  0.22127971  0.22002266  0.21653719  0.21538829  0.2134008   0.2122548\n",
      "  0.21115558  0.20797847  0.20626284  0.20541467  0.20379262  0.20250332\n",
      "  0.20160071  0.201045    0.20028931  0.19856722  0.19641835  0.19489776\n",
      "  0.1946899   0.1919572   0.19084711  0.18936763  0.188884    0.18560749\n",
      "  0.18435068  0.18366638  0.18220576  0.17960809  0.17792178  0.17778156\n",
      "  0.17663788  0.17455271  0.17426996  0.17277469  0.17199996  0.17035036\n",
      "  0.16916939  0.16813674  0.16738583  0.16692591  0.16433807  0.16324184\n",
      "  0.16251687  0.16171155  0.1607479   0.16002278  0.15857266  0.1573486\n",
      "  0.15707698  0.15665317  0.15567108  0.1541049   0.15323965  0.15277876\n",
      "  0.15191615  0.15078992  0.14955793  0.14757779  0.14714696  0.14649099\n",
      "  0.14595588  0.14508604  0.14299004  0.14244144  0.14079494  0.14014494\n",
      "  0.13929003  0.13892493  0.1382211   0.13781642  0.13481175  0.13394187\n",
      "  0.13237679  0.13177815  0.13072322  0.13035763  0.12939526  0.12779823\n",
      "  0.12736018  0.12648202  0.12516614  0.12469658  0.12416254  0.12307963\n",
      "  0.12274206  0.12215104  0.12113577  0.12089916  0.11982484  0.11888751\n",
      "  0.11690112  0.11640644  0.11622576  0.11495169  0.11438116  0.11384027\n",
      "  0.11336164  0.11271482  0.11048346  0.11014227  0.10956781  0.10902061\n",
      "  0.10748469  0.10676511  0.10561391  0.10466156  0.1044225   0.10365421\n",
      "  0.10212894  0.10199184  0.10119426  0.10054841  0.09939288  0.09836274\n",
      "  0.09806443  0.0969582   0.09639442  0.09553934  0.09507     0.09368775\n",
      "  0.09322886  0.09231718]\n"
     ]
    }
   ],
   "source": [
    "print(pca.explained_variance_)\n",
    "#eigen values를 확인할 수 있습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_std_pca = pca.fit_transform(X_train_std) #trian에 대해서 pca를 진행하였습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original shape:  (56000, 784)\n"
     ]
    }
   ],
   "source": [
    "print(\"original shape: \",X_train_std.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transformed shape: (56000, 470)\n"
     ]
    }
   ],
   "source": [
    "print(\"transformed shape:\", X_train_std_pca.shape) #원래는 70~80%의 비율을 맞추고 싶었지만 시간문제상 60%의 비율로 PCA를 진행하였습니다ㅠ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_pca = pca.transform(X_test_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original shape:  (14000, 784)\n"
     ]
    }
   ],
   "source": [
    "print(\"original shape: \", X_test_std.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transformed shape:  (14000, 470)\n"
     ]
    }
   ],
   "source": [
    "print(\"transformed shape: \", X_test_pca.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.xlabel('Number of Components')\n",
    "plt.ylabel('Variance (%)') \n",
    "plt.title('Explained Variance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "param_grid = {\n",
    "    'n_neighbors' : [3,5,7,9,10,11,13,15,17,19],\n",
    "    'weights' : ['uniform','distance'],\n",
    "    'metric' : ['euclidean', 'manhattan'] \n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    KNeighborsClassifier(),\n",
    "    param_grid,\n",
    "    verbose = 1,\n",
    "    cv = 3,\n",
    "    n_jobs = -1\n",
    ")\n",
    "#PCA를 진행한 data에 대해서 grid Search를 통하여 적절한 KNN의 파라미터를 찾아보도록 하였습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 40 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed: 132.9min\n",
      "[Parallel(n_jobs=-1)]: Done 120 out of 120 | elapsed: 399.9min finished\n",
      "C:\\Users\\gjwjd\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:739: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  self.best_estimator_.fit(X, y, **fit_params)\n"
     ]
    }
   ],
   "source": [
    "gs_results = grid_search.fit(X_train_std_pca,y_train) #train set에 대해서 grid search를 진행하였습니다.  (10시간....)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "가장 좋은 결과를 얻는 그리드 : {'metric': 'euclidean', 'n_neighbors': 3, 'weights': 'distance'}\n",
      "Best Cross-validatiy Score는 : 0.944875015271239\n",
      "test에 대해 grid_seach 알고리즘을 적용하면 : 0.9509285714285715\n"
     ]
    }
   ],
   "source": [
    "print(\"가장 좋은 결과를 얻는 그리드 : {}\".format(gs_results.best_params_))\n",
    "print(\"Best Cross-validatiy Score는 : {}\".format(gs_results.best_score_))\n",
    "print(\"test에 대해 grid_seach 알고리즘을 적용하면 : {}\".format(gs_results.score(X_test_pca,y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "grid search 결과 가장 좋은 결과를 얻는 그리드는 metric: euclidean, n_neighbors: 3, weights: distance로 출력되었습니다. \n",
    "Best Cross-Validatiy Score는 약 0.945\n",
    "test에 대하여 grid_search 알고리즘을 적용한 결과 0.95라는 만족스러운 결과가 나타나게 되었습니다. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "varInspector": {
   "cols": {
    "lenName": "1000",
    "lenType": "1000",
    "lenVar": "1000"
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "174.4px",
    "left": "600px",
    "right": "20px",
    "top": "74px",
    "width": "762.4px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
