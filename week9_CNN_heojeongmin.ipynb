{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "week9_CNN_heojeongmin.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "mount_file_id": "1fwGWiz0S8QpgvqH2ltGrokrBF5VhUcHZ",
      "authorship_tag": "ABX9TyNrqKeOMqe4xmcfgpjSUroG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jeongmin-heo/tobigs_assignment/blob/master/week9_CNN_heojeongmin.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QBU-7j5Rb9Sw",
        "colab_type": "text"
      },
      "source": [
        "# 과제 2: Residual 모델 실행\n",
        "- Colab을 활용하여 과제를 진행하도록 하겠습니다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I8sb4w9HgLKn",
        "colab_type": "code",
        "outputId": "d2717ca9-41e2-4aca-eb03-e9fc643c8575",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "cd /content/drive/My Drive/colab_workspace/ "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/colab_workspace\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fIWOGDrDdirq",
        "colab_type": "text"
      },
      "source": [
        " ## model.py에서 작성한 forwad는 다음과 같습니다. \n",
        "\n",
        "Q. [TODO] 논문의 Figure 3 형태로 forward를 구성해주세요\n",
        "  - 단, 논문의 구현과는 다른 형태이기 때문에 컨셉만 맞추어 구성하시면 됩니다.\n",
        "  - layer1, residual_layers, global_avg, fc를 조합해주세요.\n",
        "\n",
        "\n",
        "```\n",
        "\n",
        " def forward(self, x):\n",
        "        x = self.layer1(x)\n",
        "        x = self.residual_layers(x)\n",
        "        x = self.global_avg(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc(x)\n",
        "                \n",
        "        return x\n",
        "  ```     "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "biHz-b4Pj9SZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 과제를 진행하기 위한 압축파일을 풀었습니다. \n",
        "import zipfile as zf\n",
        "files = zf.ZipFile(\"week9.zip\",\"r\")\n",
        "files.extractall(\"diretory to extrat\")\n",
        "files.close\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U8Qt0dREj9Xv",
        "colab_type": "code",
        "outputId": "44cf61d5-67ab-4076-dda2-c0555ba8e6ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " \u001b[0m\u001b[01;34mbuild\u001b[0m/                 \u001b[01;34mkhaiii\u001b[0m/     \u001b[01;34mtest\u001b[0m/    \u001b[01;34mweek9\u001b[0m/\n",
            "\u001b[01;34m'diretory to extrat'\u001b[0m/   \u001b[01;34m__MACOSX\u001b[0m/   \u001b[01;34mtrain\u001b[0m/   week9.zip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rwfaUAwxj9aO",
        "colab_type": "code",
        "outputId": "fb66c565-dbf1-47c8-a403-87fdf82eb5df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "cd /content/drive/My Drive/colab_workspace/week9 #디렉토리를 이동합니다. "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Errno 2] No such file or directory: '/content/drive/My Drive/colab_workspace/week9 #디렉토리를 이동합니다.'\n",
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "67IgUWh2lYAx",
        "colab_type": "code",
        "outputId": "2e9b8fa0-cd98-4af5-b15f-a398430e7463",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34mbase\u001b[0m/        \u001b[01;34mdata_loader\u001b[0m/  \u001b[01;34mmodel\u001b[0m/           README.md  \u001b[01;34mtrainer\u001b[0m/\n",
            "config.json  LICENSE       parse_config.py  \u001b[01;34msaved\u001b[0m/     train.py\n",
            "\u001b[01;34mdata\u001b[0m/        \u001b[01;34mlogger\u001b[0m/       \u001b[01;34m__pycache__\u001b[0m/     test.py    \u001b[01;34mutils\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qh5r1Svjd-RQ",
        "colab_type": "text"
      },
      "source": [
        "# config.json \n",
        "\n",
        "```\n",
        "{\n",
        "    \"name\": \"CIFAR10_ResNet32\",\n",
        "    \"n_gpu\": 1,\n",
        "\n",
        "    \"arch\": {\n",
        "        \"type\": \"ResNet32Model\",\n",
        "        \"args\": {\"base_channels\":64}\n",
        "    },\n",
        "    \"data_loader\": {\n",
        "        \"type\": \"CIFAR10DataLoader\",\n",
        "        \"args\":{\n",
        "            \"data_dir\": \"data/\",\n",
        "            \"batch_size\": 128,\n",
        "            \"shuffle\": true,\n",
        "            \"validation_split\": 0.1,\n",
        "            \"num_workers\": 2\n",
        "        }\n",
        "    },\n",
        "    \"optimizer\": {\n",
        "        \"type\": \"SGD\",\n",
        "        \"args\":{\n",
        "            \"lr\": 0.1,\n",
        "            \"weight_decay\": 0.0001\n",
        "        }\n",
        "    },\n",
        "    \"loss\": \"cross_entropy_loss\",\n",
        "    \"metrics\": [\n",
        "        \"accuracy\", \"top_k_acc\"\n",
        "    ],\n",
        "    \"lr_scheduler\": {\n",
        "        \"type\": \"StepLR\",\n",
        "        \"args\": {\n",
        "            \"step_size\": 50,\n",
        "            \"gamma\": 0.1\n",
        "        }\n",
        "    },\n",
        "    \"trainer\": {\n",
        "        \"epochs\": 50,\n",
        "\n",
        "        \"save_dir\": \"saved/\",\n",
        "        \"save_period\": 1,\n",
        "        \"verbosity\": 2,\n",
        "        \n",
        "        \"monitor\": \"min val_loss\",\n",
        "        \"early_stop\": 10,\n",
        "\n",
        "        \"tensorboard\": true\n",
        "    }\n",
        "}\n",
        "```\n",
        "\n",
        "### config.json 을 통해 사용할 기법과 파라미터를 조절할 수 있습니다. \n",
        "- 마치 ppt의 탬플릿처럼 연구자의 분석 방향과 방식에 따라 편리하게 변경할 수 있는 장점이 있습니다. \n",
        "- 참고링크 : https://github.com/victoresque/pytorch-template \n",
        "\n",
        "\n",
        "- train.py -c config.json를 진행하였습니다. \n",
        "- ResNet32Model을 사용하고 data_loader하여 0.1비율로 validation_split하였습니다. \n",
        "- Stochastic Gradient Descent을 사용하여 최적화를 진행하고 cross entropy loss를 사용하였습니다.\n",
        "- 훈련 정보는 saved폴더에 저장하도록 하였습니다. \n",
        "- epochs는 50이지만 early_stop 조건을 추가하여 10번동안 유의미한 변화가 없을 경우 멈추도록 하겠습니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uORm5oUWYajm",
        "colab_type": "code",
        "outputId": "1de4f1d8-ae72-433d-c5bf-ed5684e30b4c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!python train.py -c config.json"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 10 [4224/45000 (9%)] Loss: 0.647548\n",
            "Train Epoch: 10 [5632/45000 (13%)] Loss: 0.453673\n",
            "Train Epoch: 10 [7040/45000 (16%)] Loss: 0.437876\n",
            "Train Epoch: 10 [8448/45000 (19%)] Loss: 0.476556\n",
            "Train Epoch: 10 [9856/45000 (22%)] Loss: 0.507134\n",
            "Train Epoch: 10 [11264/45000 (25%)] Loss: 0.390866\n",
            "Train Epoch: 10 [12672/45000 (28%)] Loss: 0.535822\n",
            "Train Epoch: 10 [14080/45000 (31%)] Loss: 0.585607\n",
            "Train Epoch: 10 [15488/45000 (34%)] Loss: 0.483016\n",
            "Train Epoch: 10 [16896/45000 (38%)] Loss: 0.473991\n",
            "Train Epoch: 10 [18304/45000 (41%)] Loss: 0.686128\n",
            "Train Epoch: 10 [19712/45000 (44%)] Loss: 0.676894\n",
            "Train Epoch: 10 [21120/45000 (47%)] Loss: 0.530834\n",
            "Train Epoch: 10 [22528/45000 (50%)] Loss: 0.540940\n",
            "Train Epoch: 10 [23936/45000 (53%)] Loss: 0.376120\n",
            "Train Epoch: 10 [25344/45000 (56%)] Loss: 0.584408\n",
            "Train Epoch: 10 [26752/45000 (59%)] Loss: 0.438758\n",
            "Train Epoch: 10 [28160/45000 (63%)] Loss: 0.509332\n",
            "Train Epoch: 10 [29568/45000 (66%)] Loss: 0.507020\n",
            "Train Epoch: 10 [30976/45000 (69%)] Loss: 0.574848\n",
            "Train Epoch: 10 [32384/45000 (72%)] Loss: 0.643152\n",
            "Train Epoch: 10 [33792/45000 (75%)] Loss: 0.355487\n",
            "Train Epoch: 10 [35200/45000 (78%)] Loss: 0.452157\n",
            "Train Epoch: 10 [36608/45000 (81%)] Loss: 0.737012\n",
            "Train Epoch: 10 [38016/45000 (84%)] Loss: 0.530433\n",
            "Train Epoch: 10 [39424/45000 (88%)] Loss: 0.336081\n",
            "Train Epoch: 10 [40832/45000 (91%)] Loss: 0.645013\n",
            "Train Epoch: 10 [42240/45000 (94%)] Loss: 0.462427\n",
            "Train Epoch: 10 [43648/45000 (97%)] Loss: 0.449744\n",
            "    epoch          : 10\n",
            "    loss           : 0.5217545758932829\n",
            "    accuracy       : 0.8184160945391414\n",
            "    top_k_acc      : 0.9663406526199495\n",
            "    val_loss       : 0.9718304842710495\n",
            "    val_accuracy   : 0.7044921875\n",
            "    val_top_k_acc  : 0.9248046875\n",
            "Saving checkpoint: saved/models/CIFAR10_ResNet32/0328_115105/checkpoint-epoch10.pth ...\n",
            "Train Epoch: 11 [0/45000 (0%)] Loss: 0.730512\n",
            "Train Epoch: 11 [1408/45000 (3%)] Loss: 0.377757\n",
            "Train Epoch: 11 [2816/45000 (6%)] Loss: 0.534281\n",
            "Train Epoch: 11 [4224/45000 (9%)] Loss: 0.447820\n",
            "Train Epoch: 11 [5632/45000 (13%)] Loss: 0.566731\n",
            "Train Epoch: 11 [7040/45000 (16%)] Loss: 0.538378\n",
            "Train Epoch: 11 [8448/45000 (19%)] Loss: 0.312262\n",
            "Train Epoch: 11 [9856/45000 (22%)] Loss: 0.448398\n",
            "Train Epoch: 11 [11264/45000 (25%)] Loss: 0.444753\n",
            "Train Epoch: 11 [12672/45000 (28%)] Loss: 0.406819\n",
            "Train Epoch: 11 [14080/45000 (31%)] Loss: 0.482394\n",
            "Train Epoch: 11 [15488/45000 (34%)] Loss: 0.537596\n",
            "Train Epoch: 11 [16896/45000 (38%)] Loss: 0.475515\n",
            "Train Epoch: 11 [18304/45000 (41%)] Loss: 0.303618\n",
            "Train Epoch: 11 [19712/45000 (44%)] Loss: 0.416379\n",
            "Train Epoch: 11 [21120/45000 (47%)] Loss: 0.379867\n",
            "Train Epoch: 11 [22528/45000 (50%)] Loss: 0.362333\n",
            "Train Epoch: 11 [23936/45000 (53%)] Loss: 0.448069\n",
            "Train Epoch: 11 [25344/45000 (56%)] Loss: 0.459705\n",
            "Train Epoch: 11 [26752/45000 (59%)] Loss: 0.526511\n",
            "Train Epoch: 11 [28160/45000 (63%)] Loss: 0.311575\n",
            "Train Epoch: 11 [29568/45000 (66%)] Loss: 0.400776\n",
            "Train Epoch: 11 [30976/45000 (69%)] Loss: 0.625464\n",
            "Train Epoch: 11 [32384/45000 (72%)] Loss: 0.469563\n",
            "Train Epoch: 11 [33792/45000 (75%)] Loss: 0.329474\n",
            "Train Epoch: 11 [35200/45000 (78%)] Loss: 0.342631\n",
            "Train Epoch: 11 [36608/45000 (81%)] Loss: 0.509478\n",
            "Train Epoch: 11 [38016/45000 (84%)] Loss: 0.415398\n",
            "Train Epoch: 11 [39424/45000 (88%)] Loss: 0.490282\n",
            "Train Epoch: 11 [40832/45000 (91%)] Loss: 0.369979\n",
            "Train Epoch: 11 [42240/45000 (94%)] Loss: 0.602123\n",
            "Train Epoch: 11 [43648/45000 (97%)] Loss: 0.550198\n",
            "    epoch          : 11\n",
            "    loss           : 0.4642372380264781\n",
            "    accuracy       : 0.8394319168244949\n",
            "    top_k_acc      : 0.9717290088383838\n",
            "    val_loss       : 0.8621935203671456\n",
            "    val_accuracy   : 0.7298828125\n",
            "    val_top_k_acc  : 0.939453125\n",
            "Saving checkpoint: saved/models/CIFAR10_ResNet32/0328_115105/checkpoint-epoch11.pth ...\n",
            "Train Epoch: 12 [0/45000 (0%)] Loss: 0.295223\n",
            "Train Epoch: 12 [1408/45000 (3%)] Loss: 0.445253\n",
            "Train Epoch: 12 [2816/45000 (6%)] Loss: 0.207629\n",
            "Train Epoch: 12 [4224/45000 (9%)] Loss: 0.395082\n",
            "Train Epoch: 12 [5632/45000 (13%)] Loss: 0.301476\n",
            "Train Epoch: 12 [7040/45000 (16%)] Loss: 0.404648\n",
            "Train Epoch: 12 [8448/45000 (19%)] Loss: 0.439214\n",
            "Train Epoch: 12 [9856/45000 (22%)] Loss: 0.341799\n",
            "Train Epoch: 12 [11264/45000 (25%)] Loss: 0.393049\n",
            "Train Epoch: 12 [12672/45000 (28%)] Loss: 0.373950\n",
            "Train Epoch: 12 [14080/45000 (31%)] Loss: 0.560967\n",
            "Train Epoch: 12 [15488/45000 (34%)] Loss: 0.458636\n",
            "Train Epoch: 12 [16896/45000 (38%)] Loss: 0.376963\n",
            "Train Epoch: 12 [18304/45000 (41%)] Loss: 0.386072\n",
            "Train Epoch: 12 [19712/45000 (44%)] Loss: 0.340401\n",
            "Train Epoch: 12 [21120/45000 (47%)] Loss: 0.394225\n",
            "Train Epoch: 12 [22528/45000 (50%)] Loss: 0.443048\n",
            "Train Epoch: 12 [23936/45000 (53%)] Loss: 0.474396\n",
            "Train Epoch: 12 [25344/45000 (56%)] Loss: 0.370777\n",
            "Train Epoch: 12 [26752/45000 (59%)] Loss: 0.363787\n",
            "Train Epoch: 12 [28160/45000 (63%)] Loss: 0.400948\n",
            "Train Epoch: 12 [29568/45000 (66%)] Loss: 0.415028\n",
            "Train Epoch: 12 [30976/45000 (69%)] Loss: 0.379676\n",
            "Train Epoch: 12 [32384/45000 (72%)] Loss: 0.522253\n",
            "Train Epoch: 12 [33792/45000 (75%)] Loss: 0.362211\n",
            "Train Epoch: 12 [35200/45000 (78%)] Loss: 0.543611\n",
            "Train Epoch: 12 [36608/45000 (81%)] Loss: 0.570954\n",
            "Train Epoch: 12 [38016/45000 (84%)] Loss: 0.441617\n",
            "Train Epoch: 12 [39424/45000 (88%)] Loss: 0.275937\n",
            "Train Epoch: 12 [40832/45000 (91%)] Loss: 0.494223\n",
            "Train Epoch: 12 [42240/45000 (94%)] Loss: 0.289854\n",
            "Train Epoch: 12 [43648/45000 (97%)] Loss: 0.324978\n",
            "    epoch          : 12\n",
            "    loss           : 0.40438579564744775\n",
            "    accuracy       : 0.8596388691603536\n",
            "    top_k_acc      : 0.977654967645202\n",
            "    val_loss       : 1.428325554728508\n",
            "    val_accuracy   : 0.7083984375\n",
            "    val_top_k_acc  : 0.9103515625\n",
            "Saving checkpoint: saved/models/CIFAR10_ResNet32/0328_115105/checkpoint-epoch12.pth ...\n",
            "Train Epoch: 13 [0/45000 (0%)] Loss: 0.446496\n",
            "Train Epoch: 13 [1408/45000 (3%)] Loss: 0.224335\n",
            "Train Epoch: 13 [2816/45000 (6%)] Loss: 0.331690\n",
            "Train Epoch: 13 [4224/45000 (9%)] Loss: 0.292050\n",
            "Train Epoch: 13 [5632/45000 (13%)] Loss: 0.359986\n",
            "Train Epoch: 13 [7040/45000 (16%)] Loss: 0.391666\n",
            "Train Epoch: 13 [8448/45000 (19%)] Loss: 0.342934\n",
            "Train Epoch: 13 [9856/45000 (22%)] Loss: 0.377638\n",
            "Train Epoch: 13 [11264/45000 (25%)] Loss: 0.359496\n",
            "Train Epoch: 13 [12672/45000 (28%)] Loss: 0.213541\n",
            "Train Epoch: 13 [14080/45000 (31%)] Loss: 0.275299\n",
            "Train Epoch: 13 [15488/45000 (34%)] Loss: 0.336700\n",
            "Train Epoch: 13 [16896/45000 (38%)] Loss: 0.350058\n",
            "Train Epoch: 13 [18304/45000 (41%)] Loss: 0.296057\n",
            "Train Epoch: 13 [19712/45000 (44%)] Loss: 0.436527\n",
            "Train Epoch: 13 [21120/45000 (47%)] Loss: 0.293943\n",
            "Train Epoch: 13 [22528/45000 (50%)] Loss: 0.339209\n",
            "Train Epoch: 13 [23936/45000 (53%)] Loss: 0.453615\n",
            "Train Epoch: 13 [25344/45000 (56%)] Loss: 0.310998\n",
            "Train Epoch: 13 [26752/45000 (59%)] Loss: 0.374414\n",
            "Train Epoch: 13 [28160/45000 (63%)] Loss: 0.452736\n",
            "Train Epoch: 13 [29568/45000 (66%)] Loss: 0.297162\n",
            "Train Epoch: 13 [30976/45000 (69%)] Loss: 0.341081\n",
            "Train Epoch: 13 [32384/45000 (72%)] Loss: 0.402112\n",
            "Train Epoch: 13 [33792/45000 (75%)] Loss: 0.180804\n",
            "Train Epoch: 13 [35200/45000 (78%)] Loss: 0.332145\n",
            "Train Epoch: 13 [36608/45000 (81%)] Loss: 0.372887\n",
            "Train Epoch: 13 [38016/45000 (84%)] Loss: 0.339006\n",
            "Train Epoch: 13 [39424/45000 (88%)] Loss: 0.379865\n",
            "Train Epoch: 13 [40832/45000 (91%)] Loss: 0.372600\n",
            "Train Epoch: 13 [42240/45000 (94%)] Loss: 0.356065\n",
            "Train Epoch: 13 [43648/45000 (97%)] Loss: 0.363915\n",
            "    epoch          : 13\n",
            "    loss           : 0.3508087042295797\n",
            "    accuracy       : 0.8786127880366162\n",
            "    top_k_acc      : 0.9825353140782828\n",
            "    val_loss       : 1.4856177523732186\n",
            "    val_accuracy   : 0.6556640625\n",
            "    val_top_k_acc  : 0.884375\n",
            "Saving checkpoint: saved/models/CIFAR10_ResNet32/0328_115105/checkpoint-epoch13.pth ...\n",
            "Train Epoch: 14 [0/45000 (0%)] Loss: 0.309507\n",
            "Train Epoch: 14 [1408/45000 (3%)] Loss: 0.155150\n",
            "Train Epoch: 14 [2816/45000 (6%)] Loss: 0.155814\n",
            "Train Epoch: 14 [4224/45000 (9%)] Loss: 0.369642\n",
            "Train Epoch: 14 [5632/45000 (13%)] Loss: 0.232643\n",
            "Train Epoch: 14 [7040/45000 (16%)] Loss: 0.332264\n",
            "Train Epoch: 14 [8448/45000 (19%)] Loss: 0.219778\n",
            "Train Epoch: 14 [9856/45000 (22%)] Loss: 0.316091\n",
            "Train Epoch: 14 [11264/45000 (25%)] Loss: 0.219343\n",
            "Train Epoch: 14 [12672/45000 (28%)] Loss: 0.243353\n",
            "Train Epoch: 14 [14080/45000 (31%)] Loss: 0.265446\n",
            "Train Epoch: 14 [15488/45000 (34%)] Loss: 0.448249\n",
            "Train Epoch: 14 [16896/45000 (38%)] Loss: 0.410608\n",
            "Train Epoch: 14 [18304/45000 (41%)] Loss: 0.502821\n",
            "Train Epoch: 14 [19712/45000 (44%)] Loss: 0.400204\n",
            "Train Epoch: 14 [21120/45000 (47%)] Loss: 0.256151\n",
            "Train Epoch: 14 [22528/45000 (50%)] Loss: 0.270412\n",
            "Train Epoch: 14 [23936/45000 (53%)] Loss: 0.216439\n",
            "Train Epoch: 14 [25344/45000 (56%)] Loss: 0.280531\n",
            "Train Epoch: 14 [26752/45000 (59%)] Loss: 0.429403\n",
            "Train Epoch: 14 [28160/45000 (63%)] Loss: 0.641059\n",
            "Train Epoch: 14 [29568/45000 (66%)] Loss: 0.303901\n",
            "Train Epoch: 14 [30976/45000 (69%)] Loss: 0.255472\n",
            "Train Epoch: 14 [32384/45000 (72%)] Loss: 0.412060\n",
            "Train Epoch: 14 [33792/45000 (75%)] Loss: 0.232533\n",
            "Train Epoch: 14 [35200/45000 (78%)] Loss: 0.291970\n",
            "Train Epoch: 14 [36608/45000 (81%)] Loss: 0.399331\n",
            "Train Epoch: 14 [38016/45000 (84%)] Loss: 0.328788\n",
            "Train Epoch: 14 [39424/45000 (88%)] Loss: 0.184763\n",
            "Train Epoch: 14 [40832/45000 (91%)] Loss: 0.188573\n",
            "Train Epoch: 14 [42240/45000 (94%)] Loss: 0.260658\n",
            "Train Epoch: 14 [43648/45000 (97%)] Loss: 0.377816\n",
            "    epoch          : 14\n",
            "    loss           : 0.30359325295483525\n",
            "    accuracy       : 0.8953228574810606\n",
            "    top_k_acc      : 0.9862393465909091\n",
            "    val_loss       : 0.8502384170889854\n",
            "    val_accuracy   : 0.7587890625\n",
            "    val_top_k_acc  : 0.944140625\n",
            "Saving checkpoint: saved/models/CIFAR10_ResNet32/0328_115105/checkpoint-epoch14.pth ...\n",
            "Train Epoch: 15 [0/45000 (0%)] Loss: 0.182095\n",
            "Train Epoch: 15 [1408/45000 (3%)] Loss: 0.192841\n",
            "Train Epoch: 15 [2816/45000 (6%)] Loss: 0.280352\n",
            "Train Epoch: 15 [4224/45000 (9%)] Loss: 0.272253\n",
            "Train Epoch: 15 [5632/45000 (13%)] Loss: 0.234508\n",
            "Train Epoch: 15 [7040/45000 (16%)] Loss: 0.238144\n",
            "Train Epoch: 15 [8448/45000 (19%)] Loss: 0.309875\n",
            "Train Epoch: 15 [9856/45000 (22%)] Loss: 0.187361\n",
            "Train Epoch: 15 [11264/45000 (25%)] Loss: 0.229275\n",
            "Train Epoch: 15 [12672/45000 (28%)] Loss: 0.150084\n",
            "Train Epoch: 15 [14080/45000 (31%)] Loss: 0.358623\n",
            "Train Epoch: 15 [15488/45000 (34%)] Loss: 0.359435\n",
            "Train Epoch: 15 [16896/45000 (38%)] Loss: 0.235148\n",
            "Train Epoch: 15 [18304/45000 (41%)] Loss: 0.164178\n",
            "Train Epoch: 15 [19712/45000 (44%)] Loss: 0.203671\n",
            "Train Epoch: 15 [21120/45000 (47%)] Loss: 0.233268\n",
            "Train Epoch: 15 [22528/45000 (50%)] Loss: 0.183791\n",
            "Train Epoch: 15 [23936/45000 (53%)] Loss: 0.390211\n",
            "Train Epoch: 15 [25344/45000 (56%)] Loss: 0.193251\n",
            "Train Epoch: 15 [26752/45000 (59%)] Loss: 0.248894\n",
            "Train Epoch: 15 [28160/45000 (63%)] Loss: 0.240233\n",
            "Train Epoch: 15 [29568/45000 (66%)] Loss: 0.149052\n",
            "Train Epoch: 15 [30976/45000 (69%)] Loss: 0.257545\n",
            "Train Epoch: 15 [32384/45000 (72%)] Loss: 0.302776\n",
            "Train Epoch: 15 [33792/45000 (75%)] Loss: 0.192398\n",
            "Train Epoch: 15 [35200/45000 (78%)] Loss: 0.176911\n",
            "Train Epoch: 15 [36608/45000 (81%)] Loss: 0.277799\n",
            "Train Epoch: 15 [38016/45000 (84%)] Loss: 0.199460\n",
            "Train Epoch: 15 [39424/45000 (88%)] Loss: 0.232997\n",
            "Train Epoch: 15 [40832/45000 (91%)] Loss: 0.176250\n",
            "Train Epoch: 15 [42240/45000 (94%)] Loss: 0.304222\n",
            "Train Epoch: 15 [43648/45000 (97%)] Loss: 0.292760\n",
            "    epoch          : 15\n",
            "    loss           : 0.256509677041322\n",
            "    accuracy       : 0.9105310921717172\n",
            "    top_k_acc      : 0.9899236505681818\n",
            "    val_loss       : 0.8764555588364601\n",
            "    val_accuracy   : 0.75546875\n",
            "    val_top_k_acc  : 0.948828125\n",
            "Saving checkpoint: saved/models/CIFAR10_ResNet32/0328_115105/checkpoint-epoch15.pth ...\n",
            "Train Epoch: 16 [0/45000 (0%)] Loss: 0.161093\n",
            "Train Epoch: 16 [1408/45000 (3%)] Loss: 0.154315\n",
            "Train Epoch: 16 [2816/45000 (6%)] Loss: 0.225698\n",
            "Train Epoch: 16 [4224/45000 (9%)] Loss: 0.318776\n",
            "Train Epoch: 16 [5632/45000 (13%)] Loss: 0.295101\n",
            "Train Epoch: 16 [7040/45000 (16%)] Loss: 0.216396\n",
            "Train Epoch: 16 [8448/45000 (19%)] Loss: 0.202809\n",
            "Train Epoch: 16 [9856/45000 (22%)] Loss: 0.299120\n",
            "Train Epoch: 16 [11264/45000 (25%)] Loss: 0.135854\n",
            "Train Epoch: 16 [12672/45000 (28%)] Loss: 0.318389\n",
            "Train Epoch: 16 [14080/45000 (31%)] Loss: 0.199238\n",
            "Train Epoch: 16 [15488/45000 (34%)] Loss: 0.250894\n",
            "Train Epoch: 16 [16896/45000 (38%)] Loss: 0.290130\n",
            "Train Epoch: 16 [18304/45000 (41%)] Loss: 0.268701\n",
            "Train Epoch: 16 [19712/45000 (44%)] Loss: 0.404128\n",
            "Train Epoch: 16 [21120/45000 (47%)] Loss: 0.220903\n",
            "Train Epoch: 16 [22528/45000 (50%)] Loss: 0.211102\n",
            "Train Epoch: 16 [23936/45000 (53%)] Loss: 0.234555\n",
            "Train Epoch: 16 [25344/45000 (56%)] Loss: 0.233876\n",
            "Train Epoch: 16 [26752/45000 (59%)] Loss: 0.210451\n",
            "Train Epoch: 16 [28160/45000 (63%)] Loss: 0.258758\n",
            "Train Epoch: 16 [29568/45000 (66%)] Loss: 0.205405\n",
            "Train Epoch: 16 [30976/45000 (69%)] Loss: 0.264030\n",
            "Train Epoch: 16 [32384/45000 (72%)] Loss: 0.142226\n",
            "Train Epoch: 16 [33792/45000 (75%)] Loss: 0.242004\n",
            "Train Epoch: 16 [35200/45000 (78%)] Loss: 0.224472\n",
            "Train Epoch: 16 [36608/45000 (81%)] Loss: 0.407032\n",
            "Train Epoch: 16 [38016/45000 (84%)] Loss: 0.286333\n",
            "Train Epoch: 16 [39424/45000 (88%)] Loss: 0.309171\n",
            "Train Epoch: 16 [40832/45000 (91%)] Loss: 0.136828\n",
            "Train Epoch: 16 [42240/45000 (94%)] Loss: 0.293343\n",
            "Train Epoch: 16 [43648/45000 (97%)] Loss: 0.411045\n",
            "    epoch          : 16\n",
            "    loss           : 0.2277609028811143\n",
            "    accuracy       : 0.9213201349431818\n",
            "    top_k_acc      : 0.991970486111111\n",
            "    val_loss       : 1.7544767647981643\n",
            "    val_accuracy   : 0.6080078125\n",
            "    val_top_k_acc  : 0.8638671875\n",
            "Saving checkpoint: saved/models/CIFAR10_ResNet32/0328_115105/checkpoint-epoch16.pth ...\n",
            "Train Epoch: 17 [0/45000 (0%)] Loss: 0.423396\n",
            "Train Epoch: 17 [1408/45000 (3%)] Loss: 0.124852\n",
            "Train Epoch: 17 [2816/45000 (6%)] Loss: 0.162200\n",
            "Train Epoch: 17 [4224/45000 (9%)] Loss: 0.142136\n",
            "Train Epoch: 17 [5632/45000 (13%)] Loss: 0.254481\n",
            "Train Epoch: 17 [7040/45000 (16%)] Loss: 0.221750\n",
            "Train Epoch: 17 [8448/45000 (19%)] Loss: 0.075927\n",
            "Train Epoch: 17 [9856/45000 (22%)] Loss: 0.137142\n",
            "Train Epoch: 17 [11264/45000 (25%)] Loss: 0.131382\n",
            "Train Epoch: 17 [12672/45000 (28%)] Loss: 0.184391\n",
            "Train Epoch: 17 [14080/45000 (31%)] Loss: 0.113969\n",
            "Train Epoch: 17 [15488/45000 (34%)] Loss: 0.173403\n",
            "Train Epoch: 17 [16896/45000 (38%)] Loss: 0.242736\n",
            "Train Epoch: 17 [18304/45000 (41%)] Loss: 0.127359\n",
            "Train Epoch: 17 [19712/45000 (44%)] Loss: 0.252711\n",
            "Train Epoch: 17 [21120/45000 (47%)] Loss: 0.361493\n",
            "Train Epoch: 17 [22528/45000 (50%)] Loss: 0.133387\n",
            "Train Epoch: 17 [23936/45000 (53%)] Loss: 0.294725\n",
            "Train Epoch: 17 [25344/45000 (56%)] Loss: 0.134472\n",
            "Train Epoch: 17 [26752/45000 (59%)] Loss: 0.220886\n",
            "Train Epoch: 17 [28160/45000 (63%)] Loss: 0.252387\n",
            "Train Epoch: 17 [29568/45000 (66%)] Loss: 0.337245\n",
            "Train Epoch: 17 [30976/45000 (69%)] Loss: 0.203475\n",
            "Train Epoch: 17 [32384/45000 (72%)] Loss: 0.247066\n",
            "Train Epoch: 17 [33792/45000 (75%)] Loss: 0.277106\n",
            "Train Epoch: 17 [35200/45000 (78%)] Loss: 0.169593\n",
            "Train Epoch: 17 [36608/45000 (81%)] Loss: 0.280519\n",
            "Train Epoch: 17 [38016/45000 (84%)] Loss: 0.220187\n",
            "Train Epoch: 17 [39424/45000 (88%)] Loss: 0.239629\n",
            "Train Epoch: 17 [40832/45000 (91%)] Loss: 0.231616\n",
            "Train Epoch: 17 [42240/45000 (94%)] Loss: 0.159032\n",
            "Train Epoch: 17 [43648/45000 (97%)] Loss: 0.195168\n",
            "    epoch          : 17\n",
            "    loss           : 0.1996627266688103\n",
            "    accuracy       : 0.9310537010732323\n",
            "    top_k_acc      : 0.9937460542929292\n",
            "    val_loss       : 1.207940411567688\n",
            "    val_accuracy   : 0.7158203125\n",
            "    val_top_k_acc  : 0.9158203125\n",
            "Saving checkpoint: saved/models/CIFAR10_ResNet32/0328_115105/checkpoint-epoch17.pth ...\n",
            "Train Epoch: 18 [0/45000 (0%)] Loss: 0.192865\n",
            "Train Epoch: 18 [1408/45000 (3%)] Loss: 0.242801\n",
            "Train Epoch: 18 [2816/45000 (6%)] Loss: 0.218230\n",
            "Train Epoch: 18 [4224/45000 (9%)] Loss: 0.103442\n",
            "Train Epoch: 18 [5632/45000 (13%)] Loss: 0.113269\n",
            "Train Epoch: 18 [7040/45000 (16%)] Loss: 0.129081\n",
            "Train Epoch: 18 [8448/45000 (19%)] Loss: 0.180973\n",
            "Train Epoch: 18 [9856/45000 (22%)] Loss: 0.150468\n",
            "Train Epoch: 18 [11264/45000 (25%)] Loss: 0.211060\n",
            "Train Epoch: 18 [12672/45000 (28%)] Loss: 0.112223\n",
            "Train Epoch: 18 [14080/45000 (31%)] Loss: 0.189760\n",
            "Train Epoch: 18 [15488/45000 (34%)] Loss: 0.225576\n",
            "Train Epoch: 18 [16896/45000 (38%)] Loss: 0.200852\n",
            "Train Epoch: 18 [18304/45000 (41%)] Loss: 0.140621\n",
            "Train Epoch: 18 [19712/45000 (44%)] Loss: 0.216620\n",
            "Train Epoch: 18 [21120/45000 (47%)] Loss: 0.112231\n",
            "Train Epoch: 18 [22528/45000 (50%)] Loss: 0.107806\n",
            "Train Epoch: 18 [23936/45000 (53%)] Loss: 0.199932\n",
            "Train Epoch: 18 [25344/45000 (56%)] Loss: 0.136068\n",
            "Train Epoch: 18 [26752/45000 (59%)] Loss: 0.111665\n",
            "Train Epoch: 18 [28160/45000 (63%)] Loss: 0.155202\n",
            "Train Epoch: 18 [29568/45000 (66%)] Loss: 0.146008\n",
            "Train Epoch: 18 [30976/45000 (69%)] Loss: 0.180206\n",
            "Train Epoch: 18 [32384/45000 (72%)] Loss: 0.211451\n",
            "Train Epoch: 18 [33792/45000 (75%)] Loss: 0.326327\n",
            "Train Epoch: 18 [35200/45000 (78%)] Loss: 0.163794\n",
            "Train Epoch: 18 [36608/45000 (81%)] Loss: 0.107303\n",
            "Train Epoch: 18 [38016/45000 (84%)] Loss: 0.109667\n",
            "Train Epoch: 18 [39424/45000 (88%)] Loss: 0.230654\n",
            "Train Epoch: 18 [40832/45000 (91%)] Loss: 0.242670\n",
            "Train Epoch: 18 [42240/45000 (94%)] Loss: 0.276304\n",
            "Train Epoch: 18 [43648/45000 (97%)] Loss: 0.229265\n",
            "    epoch          : 18\n",
            "    loss           : 0.16855512705462222\n",
            "    accuracy       : 0.9425800978535354\n",
            "    top_k_acc      : 0.9955043600063131\n",
            "    val_loss       : 0.8502751857042312\n",
            "    val_accuracy   : 0.772265625\n",
            "    val_top_k_acc  : 0.94375\n",
            "Saving checkpoint: saved/models/CIFAR10_ResNet32/0328_115105/checkpoint-epoch18.pth ...\n",
            "Train Epoch: 19 [0/45000 (0%)] Loss: 0.198620\n",
            "Train Epoch: 19 [1408/45000 (3%)] Loss: 0.188527\n",
            "Train Epoch: 19 [2816/45000 (6%)] Loss: 0.190421\n",
            "Train Epoch: 19 [4224/45000 (9%)] Loss: 0.110388\n",
            "Train Epoch: 19 [5632/45000 (13%)] Loss: 0.099145\n",
            "Train Epoch: 19 [7040/45000 (16%)] Loss: 0.177364\n",
            "Train Epoch: 19 [8448/45000 (19%)] Loss: 0.245623\n",
            "Train Epoch: 19 [9856/45000 (22%)] Loss: 0.183261\n",
            "Train Epoch: 19 [11264/45000 (25%)] Loss: 0.191638\n",
            "Train Epoch: 19 [12672/45000 (28%)] Loss: 0.118890\n",
            "Train Epoch: 19 [14080/45000 (31%)] Loss: 0.221194\n",
            "Train Epoch: 19 [15488/45000 (34%)] Loss: 0.143177\n",
            "Train Epoch: 19 [16896/45000 (38%)] Loss: 0.202944\n",
            "Train Epoch: 19 [18304/45000 (41%)] Loss: 0.141563\n",
            "Train Epoch: 19 [19712/45000 (44%)] Loss: 0.095350\n",
            "Train Epoch: 19 [21120/45000 (47%)] Loss: 0.342173\n",
            "Train Epoch: 19 [22528/45000 (50%)] Loss: 0.213733\n",
            "Train Epoch: 19 [23936/45000 (53%)] Loss: 0.212816\n",
            "Train Epoch: 19 [25344/45000 (56%)] Loss: 0.127652\n",
            "Train Epoch: 19 [26752/45000 (59%)] Loss: 0.121728\n",
            "Train Epoch: 19 [28160/45000 (63%)] Loss: 0.101594\n",
            "Train Epoch: 19 [29568/45000 (66%)] Loss: 0.088467\n",
            "Train Epoch: 19 [30976/45000 (69%)] Loss: 0.137877\n",
            "Train Epoch: 19 [32384/45000 (72%)] Loss: 0.202659\n",
            "Train Epoch: 19 [33792/45000 (75%)] Loss: 0.136543\n",
            "Train Epoch: 19 [35200/45000 (78%)] Loss: 0.139461\n",
            "Train Epoch: 19 [36608/45000 (81%)] Loss: 0.196010\n",
            "Train Epoch: 19 [38016/45000 (84%)] Loss: 0.180452\n",
            "Train Epoch: 19 [39424/45000 (88%)] Loss: 0.105846\n",
            "Train Epoch: 19 [40832/45000 (91%)] Loss: 0.330209\n",
            "Train Epoch: 19 [42240/45000 (94%)] Loss: 0.105602\n",
            "Train Epoch: 19 [43648/45000 (97%)] Loss: 0.142875\n",
            "    epoch          : 19\n",
            "    loss           : 0.15279663026078857\n",
            "    accuracy       : 0.9477637705176768\n",
            "    top_k_acc      : 0.9962269176136364\n",
            "    val_loss       : 0.8057778134942055\n",
            "    val_accuracy   : 0.79375\n",
            "    val_top_k_acc  : 0.9515625\n",
            "Validation performance didn't improve for 10 epochs. Training stops.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KgDW91ZlgVzH",
        "colab_type": "text"
      },
      "source": [
        "- 나온정보를 토대로 \"0328_091030\"에 저장되어있는 모델이 best model임을 알 수 있었습니다. \n",
        "- 이를 토대로 test를 진행해보았습니다. \n",
        "**- <colab은 경로에 \"경로\"를 붙혀야 합니다>**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XqEpzCUvL4am",
        "colab_type": "code",
        "outputId": "f908dcd6-465c-4a9c-8e09-58061af6f932",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!python test.py --resume \"/content/drive/My Drive/colab_workspace/week9/saved/models/CIFAR10_ResNet32/0328_091030/model_best.pth\" "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "ResNet32Model(\n",
            "  (layer1): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU()\n",
            "  )\n",
            "  (residual_layers): Sequential(\n",
            "    (0): ResidualBlock(\n",
            "      (residual_layer): Sequential(\n",
            "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU()\n",
            "        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (5): ReLU()\n",
            "      )\n",
            "    )\n",
            "    (1): ResidualBlock(\n",
            "      (residual_layer): Sequential(\n",
            "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU()\n",
            "        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (5): ReLU()\n",
            "      )\n",
            "    )\n",
            "    (2): ResidualBlock(\n",
            "      (residual_layer): Sequential(\n",
            "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU()\n",
            "        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (5): ReLU()\n",
            "      )\n",
            "    )\n",
            "    (3): ResidualBlock(\n",
            "      (residual_layer): Sequential(\n",
            "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU()\n",
            "        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (5): ReLU()\n",
            "      )\n",
            "    )\n",
            "    (4): ResidualBlock(\n",
            "      (residual_layer): Sequential(\n",
            "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU()\n",
            "        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (5): ReLU()\n",
            "      )\n",
            "    )\n",
            "    (5): ResidualBlock(\n",
            "      (residual_layer): Sequential(\n",
            "        (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU()\n",
            "        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (5): ReLU()\n",
            "      )\n",
            "      (conv1_layer): Sequential(\n",
            "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2))\n",
            "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU()\n",
            "      )\n",
            "    )\n",
            "    (6): ResidualBlock(\n",
            "      (residual_layer): Sequential(\n",
            "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU()\n",
            "        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (5): ReLU()\n",
            "      )\n",
            "    )\n",
            "    (7): ResidualBlock(\n",
            "      (residual_layer): Sequential(\n",
            "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU()\n",
            "        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (5): ReLU()\n",
            "      )\n",
            "    )\n",
            "    (8): ResidualBlock(\n",
            "      (residual_layer): Sequential(\n",
            "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU()\n",
            "        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (5): ReLU()\n",
            "      )\n",
            "    )\n",
            "    (9): ResidualBlock(\n",
            "      (residual_layer): Sequential(\n",
            "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU()\n",
            "        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (5): ReLU()\n",
            "      )\n",
            "    )\n",
            "    (10): ResidualBlock(\n",
            "      (residual_layer): Sequential(\n",
            "        (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU()\n",
            "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (5): ReLU()\n",
            "      )\n",
            "      (conv1_layer): Sequential(\n",
            "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2))\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU()\n",
            "      )\n",
            "    )\n",
            "    (11): ResidualBlock(\n",
            "      (residual_layer): Sequential(\n",
            "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU()\n",
            "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (5): ReLU()\n",
            "      )\n",
            "    )\n",
            "    (12): ResidualBlock(\n",
            "      (residual_layer): Sequential(\n",
            "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU()\n",
            "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (5): ReLU()\n",
            "      )\n",
            "    )\n",
            "    (13): ResidualBlock(\n",
            "      (residual_layer): Sequential(\n",
            "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU()\n",
            "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (5): ReLU()\n",
            "      )\n",
            "    )\n",
            "    (14): ResidualBlock(\n",
            "      (residual_layer): Sequential(\n",
            "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU()\n",
            "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (5): ReLU()\n",
            "      )\n",
            "    )\n",
            "    (15): ResidualBlock(\n",
            "      (residual_layer): Sequential(\n",
            "        (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU()\n",
            "        (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (5): ReLU()\n",
            "      )\n",
            "      (conv1_layer): Sequential(\n",
            "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2))\n",
            "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU()\n",
            "      )\n",
            "    )\n",
            "    (16): ResidualBlock(\n",
            "      (residual_layer): Sequential(\n",
            "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU()\n",
            "        (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (5): ReLU()\n",
            "      )\n",
            "    )\n",
            "    (17): ResidualBlock(\n",
            "      (residual_layer): Sequential(\n",
            "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU()\n",
            "        (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (5): ReLU()\n",
            "      )\n",
            "    )\n",
            "    (18): ResidualBlock(\n",
            "      (residual_layer): Sequential(\n",
            "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU()\n",
            "        (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (5): ReLU()\n",
            "      )\n",
            "    )\n",
            "    (19): ResidualBlock(\n",
            "      (residual_layer): Sequential(\n",
            "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU()\n",
            "        (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (5): ReLU()\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (global_avg): AvgPool2d(kernel_size=4, stride=4, padding=0)\n",
            "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
            ")\n",
            "Trainable parameters: 29996682\n",
            "Loading checkpoint: /content/drive/My Drive/colab_workspace/week9/saved/models/CIFAR10_ResNet32/0328_091030/model_best.pth ...\n",
            "100% 20/20 [00:07<00:00,  2.80it/s]\n",
            "{'loss': 0.8257985265731812, 'accuracy': 0.7246, 'top_k_acc': 0.9289}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eX_mll2ogi1y",
        "colab_type": "text"
      },
      "source": [
        "- 'loss' = 0.8257985265731812\n",
        "- 'accuracy' = 0.7246\n",
        "- 'top_k_acc'=  0.9289\n",
        "\n",
        "```\n",
        "def top_k_acc(output, target, k=3):\n",
        "    with torch.no_grad():\n",
        "        pred = torch.topk(output, k, dim=1)[1]\n",
        "        assert pred.shape[0] == len(target)\n",
        "        correct = 0\n",
        "        for i in range(k):\n",
        "            correct += torch.sum(pred[:, i] == target).item()\n",
        "    return correct / len(target)\n",
        "```\n",
        "\n",
        "\n",
        "- 일반적으로  top-1, top-5 acc를 많이 쓰는데 데이터의 클래스를 예측해서 확률값이 높은 k를 나열했을 때, k개 안에 진짜 정답이 포함되면 잘 예측한 것으로 판단하는 방식입니다.\n",
        "- metric.py를 참고했을때 top_k_acc의 k는 **3**인 것을 알 수 있었습니다. \n",
        "- top 3를 예측했을때는 기존의 0.72보다 굉장히 높은 0.92로 나타는 것을 알 수 있었습니다. \n",
        "\n",
        "\n",
        "## tensorboard\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "04jyyKbnjjhx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install tensorboard>=1.14.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "15fne8WokEcR",
        "colab_type": "code",
        "outputId": "e87d52ac-cbaf-42b9-b1d7-d9e9d41c6436",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        }
      },
      "source": [
        "!pip install tensorboardX"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorboardX in /usr/local/lib/python3.6/dist-packages (2.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (1.18.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (1.12.0)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (3.10.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.8.0->tensorboardX) (46.0.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IvnA9xU2laCh",
        "colab_type": "code",
        "outputId": "6d47d44f-5edd-433d-a2e3-2289995b473b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        }
      },
      "source": [
        "!pip install 'git+https://github.com/lanpa/tensorboardX'"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/lanpa/tensorboardX\n",
            "  Cloning https://github.com/lanpa/tensorboardX to /tmp/pip-req-build-ie38uwn9\n",
            "  Running command git clone -q https://github.com/lanpa/tensorboardX /tmp/pip-req-build-ie38uwn9\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from tensorboardX==2.0+d09aeb8) (1.18.2)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorboardX==2.0+d09aeb8) (3.10.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from tensorboardX==2.0+d09aeb8) (1.12.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.8.0->tensorboardX==2.0+d09aeb8) (46.0.0)\n",
            "Building wheels for collected packages: tensorboardX\n",
            "  Building wheel for tensorboardX (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tensorboardX: filename=tensorboardX-2.0+d09aeb8-py2.py3-none-any.whl size=119726 sha256=b7ee19e217f0a6c3f7ce6bb7b239d236e368c5ee2984e1a57b3378dc26363968\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-iizplw21/wheels/57/88/4d/30b1e9e2093375d22a0701b666d7e57f71d50cbdf8cc5998c4\n",
            "Successfully built tensorboardX\n",
            "Installing collected packages: tensorboardX\n",
            "  Found existing installation: tensorboardX 2.0\n",
            "    Uninstalling tensorboardX-2.0:\n",
            "      Successfully uninstalled tensorboardX-2.0\n",
            "Successfully installed tensorboardX-2.0+d09aeb8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jqvw5wRujpwT",
        "colab_type": "code",
        "outputId": "fdc6c869-e9d0-486b-957a-6478b9040f74",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341
        }
      },
      "source": [
        "!tensorboard --logdir \"/content/drive/My Drive/colab_workspace/week9/logger/visualization.py\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-03-28 19:35:06.328640: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "Exception in thread Reloader:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.6/threading.py\", line 864, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorboard/backend/application.py\", line 586, in _reload\n",
            "    multiplexer.AddRunsFromDirectory(path, name)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorboard/backend/event_processing/plugin_event_multiplexer.py\", line 199, in AddRunsFromDirectory\n",
            "    for subdir in io_wrapper.GetLogdirSubdirectories(path):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorboard/backend/event_processing/io_wrapper.py\", line 181, in GetLogdirSubdirectories\n",
            "    \"GetLogdirSubdirectories: path exists and is not a \" \"directory, %s\" % path\n",
            "ValueError: GetLogdirSubdirectories: path exists and is not a directory, /content/drive/My Drive/colab_workspace/week9/logger/visualization.py\n",
            "\n",
            "Serving TensorBoard on localhost; to expose to the network, use a proxy or pass --bind_all\n",
            "TensorBoard 2.1.1 at http://localhost:6006/ (Press CTRL+C to quit)\n",
            "^C\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AL564SDGlksT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}