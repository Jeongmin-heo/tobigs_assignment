{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment2 - Logistic Regression 구현\n",
    "none으로 구성된 영역에 대해서 채워보았습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math, random\n",
    "from functools import partial,reduce\n",
    "from assignment2 import *\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data 설명\n",
    "1) Label: 유료 계정 등록 여부(target)\n",
    "2) bias: 회귀 모형에서의 상수항을 위한 term (추정 시 포함하지 않아도 ok)\n",
    "3) experience: 근속연수\n",
    "4) salary: 연봉\n",
    "\n",
    "어떤 사용자가 유료 계정을 등록할지(Label == 1)에 대한 예측을 로지스틱 회귀 모형으로 진행합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('assignment_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>bias</th>\n",
       "      <th>experience</th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.7</td>\n",
       "      <td>48000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.9</td>\n",
       "      <td>48000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>60000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.2</td>\n",
       "      <td>63000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>76000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>195</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.5</td>\n",
       "      <td>84000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>196</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.9</td>\n",
       "      <td>73000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>197</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5.1</td>\n",
       "      <td>72000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>198</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9.1</td>\n",
       "      <td>69000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>199</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9.8</td>\n",
       "      <td>79000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Label  bias  experience  salary\n",
       "0        1     1         0.7   48000\n",
       "1        0     1         1.9   48000\n",
       "2        1     1         2.5   60000\n",
       "3        0     1         4.2   63000\n",
       "4        0     1         6.0   76000\n",
       "..     ...   ...         ...     ...\n",
       "195      0     1         6.5   84000\n",
       "196      0     1         6.9   73000\n",
       "197      0     1         5.1   72000\n",
       "198      1     1         9.1   69000\n",
       "199      1     1         9.8   79000\n",
       "\n",
       "[200 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#0이될때 가장 작은 지점이라고 볼 수 있다. 따라서 벡터 v가 direction으로 step_size 만큼 이동한 것을 v2, direction2으로 지정하는 함수를 만듭니다.\n",
    "\n",
    "def step(v, direction, step_size):\n",
    "    return [v2 + step_size * direction2 for v2, direction2 in zip(v,direction)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe(f) :\n",
    "    \"\"\"\n",
    "    f에 대한 예외처리를 위한 함수(f가 infinite일 때)\n",
    "    \"\"\"\n",
    "    def safe_f(*args, **kwargs):\n",
    "        try:\n",
    "            return f(*args, **kwargs)\n",
    "        except:\n",
    "            return float('inf')\n",
    "    return safe_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 가장 적합한 모델을 찾기위해서는 1)모델의 오류를 최소화하거나 2)우도를 최대화 하는 방법이 있습니다.\n",
    "# 이를위해 경사하강법 gradient을 사용합니다.\n",
    "#즉, 함수가 가장 빠르게 증가할 수 있는 방향을 찾아야 하는데 임의의 시작점에서 gradient를 계산하고 그 gradient방향으로 조금씩 이동하는 것을 반복해야합니다.\n",
    "#목적함수를 최소화시키는 theta를 경사 하강법을 사용해서 찾는다.\n",
    "\n",
    "def minimize_bgd(target_fn, gradient_fn, theta_0, tolerance = 0.00001): # bgd: batch gradient descent\n",
    "    step_sizes = [100, 10, 1, 0.1, 0.01, 0.001, 0.0001, 0.00001]\n",
    "    \n",
    "    # 시작점 설정\n",
    "    theta = theta_0 #시작점\n",
    "    target_fn = safe(target_fn) # 오류를 처리할 수 있도록 target_fn에 safe함수를 사용하여 변환합니다\n",
    "    value = target_fn(theta) # 최소화시키려는 값을 value로하여 target_fn에 theta를 넣습니다\n",
    "    \n",
    "    while True:\n",
    "        gradient = gradient_fn(theta) # gradient값을 계산합니다\n",
    "        next_thetas = [step(theta,gradient, -step_size) for step_size in step_sizes] #### update thetas --> 각 step sizes에 따른 theta값을 list형태로 리턴\n",
    "        #next_thetas는 theta가 gradient방향으로 -step_size(점점작아지도록)만큼 이동하도록 합니다. \n",
    "        # 함수를 최소화시키는 theta 선택\n",
    "        obj = next_thetas #obj라는 이름으로 next_thetas를 지정합니다. \n",
    "        #print(obj)\n",
    "        key = target_fn #key라는 이름으로 target_fn을 지정합니다. \n",
    "        #print(key)\n",
    "        next_theta = min(obj, key = key) #next_thetas가 최소화되는 방향으로 이동한 것을 다시 next_theta로 지정합니다 \n",
    "        #print(next_theta)\n",
    "        next_value = target_fn(next_theta) # next_theta에서 최소화 되는 지점을 next_value라고 지정합니다. \n",
    "        #print(next_value)\n",
    "        \n",
    "        # tolerance만큼 수렴하면 멈춤\n",
    "        temp = abs(next_value - value) #오류값이 우리가 설정한 tolerance(용인가능한 범위)보다 작을경우경우 반복문에서 벗어나고자합니다. \n",
    "        \n",
    "        # temp가 음수일 경우도 있기 때문에 절대값을 씌어 주어야 합니다. \n",
    "        if temp < tolerance:\n",
    "            return theta #이 지점에서의 theta를 return합니다 \n",
    "        else: \n",
    "            theta, value = next_theta, next_value #temp가 tolerance보다 클경우 다시 이동하기 위하여 다시 새로운 theta, value로 돌아가야 합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stochastic():\n",
    "    \"\"\"\n",
    "    sgd 구현 (추가적인 부분이니 필수는 아닙니다.)\n",
    "    random sampling 하는 부분(함수로 따로 구현하셔도 ok) + gd 부분\n",
    "    \"\"\"\n",
    "    #죄송합니다..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 로지스틱 함수\n",
    "해당 함수는 1/(1+exp[-(ax+b)]로 표현되었음을 기억합시다.# 1. 로지스틱"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic(x):\n",
    "    try:\n",
    "        return 1.0 / (1 + math.exp(-x))\n",
    "    except OverflowError:\n",
    "        return 1e-9 #OverflowError함수를 사용하여 예외처리를 해주었습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax():\n",
    "    e_x = np.exp(x - np.max(x))\n",
    "    return e_x / e_x.sum()\n",
    "#softmax 정의이기때문에..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Likelihood 구현\n",
    "그냥 Likelihood function 대신, log likelihood function을 이용해서 구현하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Likelihood 의 미분해서 0이 되는 값을 찾아야 하는데, 복잡하기 때문에 Log를 취하며 이것을 Log Likelihood라고 합니다. \n",
    "def logistic_log_likelihood_i(x_i, y_i, beta): # 개별 데이터포인트에 대한 likelihood 값\n",
    "    if y_i == 1:\n",
    "        return math.log(logistic(dot(x_i, beta)))\n",
    "        #likelihood에 log를 씌우고 y_i이 1이나올경우를 x_i에 beta의 곱에 대한 결과에 log를 씌우고\n",
    "    else:\n",
    "        return math.log(1 - logistic(dot(x_i, beta))+1e-9)\n",
    "    #나머지의 경우를 로그를 씌웁니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_log_likelihood(x,y,beta): # 전체 데이터에 대한 likelihood\n",
    "    return sum(logistic_log_likelihood_i(x_i, y_i, beta)\n",
    "               for x_i, y_i in zip(x, y))\n",
    "#같은 방식으로 데이터 전체에 대한 전체합에 대한 우도를 로그를 씌웁니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3번부터는 공지방의 소스코드 활용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Gradient for Log Reg\n",
    "아래 3가지 함수에 대해 해당 함수의 인자와 기능을 자세히 설명하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_log_partial_ij(x_i, y_i, beta, j):\n",
    "    \"\"\"\n",
    "    특정 데이터 x_i에 대한 beta_j의 gradient 값 --> 상수 형태의 리턴값\n",
    "    \"\"\"\n",
    "    return (y_i - logistic(dot(x_i, beta))) * x_i[j] # j: beta의 index\n",
    "\n",
    "def logistic_log_gradient_i(x_i, y_i, beta):\n",
    "    \"\"\"\n",
    "    x_i(row)에 대한 beta의 gradient 값(column 개수만큼) --> 리스트 형태의 리턴값을 가짐\n",
    "    \"\"\"\n",
    "    return [logistic_log_partial_ij(x_i, y_i, beta, j) for j, _ in enumerate(beta)]\n",
    "\n",
    "def logistic_log_gradient(x, y, beta):\n",
    "    \"\"\"\n",
    "    전체 데이터에 대한 beta의 gradient 값 \n",
    "    --> 이중 리스트를 vector_add 시켜서 beta_j에 대한 gradient값들을 rowSum 해놓은 리스트를 리턴\n",
    "    \"\"\"\n",
    "    return reduce(vector_add, [logistic_log_gradient_i(x_i, y_i, beta) for x_i, y_i in zip(x,y)])\n",
    "# reduce ~ == np.sum(iter, axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Model Fitting\n",
    "위에서 구현한 log likelihood를 이용하여 Model을 Fitting 시켜보세요.  \n",
    "앞서 우리는 log likelihood를 maximize하는 방향으로 회귀계수를 추정한다고 배웠습니다.  \n",
    "Gradient Descent는 경사 \"하강법\"으로 최솟값을 찾는 데에 사용되는 알고리즘입니다.  \n",
    "따라서 log likelihood를 적절히 변형을 해야 Gradient Descent 코드를 적용할 수 있습니다.  \n",
    "log likelihood 변형 함수는 assignment2.py에 구현되어있으니, None값만 채워주시면 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>bias</th>\n",
       "      <th>experience</th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.7</td>\n",
       "      <td>48000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.9</td>\n",
       "      <td>48000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>60000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.2</td>\n",
       "      <td>63000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>76000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>195</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.5</td>\n",
       "      <td>84000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>196</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.9</td>\n",
       "      <td>73000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>197</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5.1</td>\n",
       "      <td>72000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>198</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9.1</td>\n",
       "      <td>69000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>199</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9.8</td>\n",
       "      <td>79000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Label  bias  experience  salary\n",
       "0        1     1         0.7   48000\n",
       "1        0     1         1.9   48000\n",
       "2        1     1         2.5   60000\n",
       "3        0     1         4.2   63000\n",
       "4        0     1         6.0   76000\n",
       "..     ...   ...         ...     ...\n",
       "195      0     1         6.5   84000\n",
       "196      0     1         6.9   73000\n",
       "197      0     1         5.1   72000\n",
       "198      1     1         9.1   69000\n",
       "199      1     1         9.8   79000\n",
       "\n",
       "[200 rows x 4 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop('Label', axis = 1)\n",
    "y = data['Label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gjwjd\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "C:\\Users\\gjwjd\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "X=X.as_matrix() # matrix로 변환해주어야 합니다!\n",
    "y=y.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.0e+00, 7.0e-01, 4.8e+04],\n",
       "       [1.0e+00, 1.9e+00, 4.8e+04],\n",
       "       [1.0e+00, 2.5e+00, 6.0e+04],\n",
       "       [1.0e+00, 4.2e+00, 6.3e+04],\n",
       "       [1.0e+00, 6.0e+00, 7.6e+04],\n",
       "       [1.0e+00, 6.5e+00, 6.9e+04],\n",
       "       [1.0e+00, 7.5e+00, 7.6e+04],\n",
       "       [1.0e+00, 8.1e+00, 8.8e+04],\n",
       "       [1.0e+00, 8.7e+00, 8.3e+04],\n",
       "       [1.0e+00, 1.0e+01, 8.3e+04]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:10] ## X: 데이터 스케일이 필요함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "ss = StandardScaler()\n",
    "X_scaled = ss.fit_transform(data.drop(['Label'], axis = 1)) # X_scaled\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,_ in enumerate(X_scaled):\n",
    "    X_scaled[i][0] = 1 # bias term 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(0)\n",
    "x_train, x_test, y_train, y_test = train_test_split(X_scaled, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 아래에 Model Fitting 진행\n",
    "# partial을 이용해 fn과 gradient_fn 구현\n",
    "\n",
    "fn = partial(logistic_log_likelihood, x_train, y_train)\n",
    "gradient_fn = partial(logistic_log_gradient, x_train, y_train)\n",
    "\n",
    "beta_0 = [random.random() for _ in range(3)] # 임의의 시작점\n",
    "#beta_0 = [1,1,1]\n",
    "\n",
    "# 경사 하강법으로 최적화\n",
    "beta_hat = minimize_bgd(neg(fn), neg_all(gradient_fn), beta_0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-1.9572843730755123, 4.4450391911094265, -4.104964259568767]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beta_hat"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
